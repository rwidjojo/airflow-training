# 18. Branching and Conditional Task

## 18.1 Branching

Imagine that you just finished writing the ingestion of order data in your DAG, when your co-worker comes in with some news. Apparently management decided that they are going to
switch calculation logic, which means that our order data will be have different logic (and of course in a different format).

Of course, this change should not result in any disruption in the training our model. Moreover, they would like us to keep our flow compatible with both the old and new calculation logic, so that we can continue to use historical order data in our future analyses.

For our convinience, we will differentiate calculation based on `execution_date`:

- If `execution_date` is odd like `2020-12-01` then there are no change on data count
- If `execution_date` is even like `2020-12-02` then data count will multiply by 2

### 18.1.1 Branching within tasks

One approach could be to rewrite our order ingestion tasks to check the current execution date and use that to decide between two separate code paths for ingesting and processing the order
data.

For example, we could rewrite our migrate data task to something like this

```python
def migrate_odd_day(ds, **kwargs):
  # migrate on odd day

def migrate_even_day(ds, **kwargs):
  # migrate on even day


def migrate_data(**kwargs):
  execution_date = kwargs['execution_date']
  if execution_date.day % 2 == 0:
    migrate_even_day(**kwargs)
  else:
    migrate_odd_day(**kwargs)
```

An advantage of this approach is that it allows us to incorporate some flexibility in our DAGs without having to modify the structure of the DAG itself. However, this approach only works in cases where the branches in our code consist of similar tasks.

If there are case when two branches have different set of task like this:

<img src="./imgs/1-two-different-line-proccess.png"/>

At that case we may be better off splitting our
data ingestion into two separate sets of tasks.

Another drawback of this approach is that it is difficult to see which code branch is being used by Airflow during a specific DAG run.

### 18.1.2 Branching within the DAG

Another way to support the two different systems in a single DAG is to develop two distinct sets of tasks (one for each system) and allow the DAG to choose whether to execute the tasks for fetching data from either the old or new system

<img src="./imgs/2-dag-branching.png"/>

We could your module `BranchPythonOperator`

```python
from airflow.operators.python_operator import BranchPythonOperator

def _pick_migration(**kwargs):
  execution_date = kwargs['execution_date']
  if execution_date.day % 2 == 0:
    return 'migrate_even' # returning task id `migrate_even_task`
  else:
    return 'migrate_odd' # returning task id `migrate_odd_task`


migration_branch = BranchPythonOperator(
  task_id='migration_branch',
  provide_context=True,
  python_callable=_pick_migration,
  dag=dag
)

migration_branch >> [migrate_even_task, migrate_odd_task]

```

## 18.2 Conditional Task

Besides branches, Airflow also provides you with other mechanisms for skipping specific tasks in your DAG depending on certain conditions.

This allows you to make certain tasks run only if
certain datasets are available, or only if your DAG is executing for the most recent execution
date.

For example, consider a situation in which you would like to add a task to your DAG that notifies you whenever it successfully run. However, a few days after adding this task to the DAG, you get flooded with notifications because your co-worker decided to backfill the DAG for its entire history to make
some changes to how the data is imported.

To avoid a similar deluge of notification in the
future, you would like to modify your DAG to only send notifications for the most recent DAG run.

```python
def _notify(**context):
  if context["execution_date"] == ...:
  send_notification()

notify = PythonOperator(
  task_id="notify",
  python_callable=_notify,
  provide_context=True
)
```

Another way to implement conditional notifications is to make the notification task itself conditional

```python
def_latest_only(**context):
  ...


if_most_recent = PythonOperator(
  task_id="latest_only",
  python_callable=_latest_only,
  provide_context=True,
  dag=dag,
)

if_most_recent >> notify

```

def_latest_only could use module `AirflowSkipException`

```python
from airflow.exceptions import AirflowSkipException

def _latest_only(**context):
  # Find the boundaries for our execution window.
  left_window = context['dag'].following_schedule(context['execution_date'])
  right_window = context['dag'].following_schedule(left_window)

  # Check if our current time is within the window.
  now = pendulum.utcnow()
  if not left_window < now <= right_window:
    raise AirflowSkipException("Not the most recent run!")
```
