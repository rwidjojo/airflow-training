# 10. Operators & Sensors

While DAGs describe how to run a workflow, Operators determine what gets done.

An operator describes a single task in a workflow. Operators are usually (but not always) atomic, meaning they can stand on their own and donâ€™t need to share resources with any other operators. The DAG will make sure that operators run in the certain correct order; other than those dependencies, operators generally run independently. They may run on two completely different machines.

There are over 100 operators shipped with Airflow. Airflow operators can be broadly categorized into three categories.

### Action Operators:

The action operators perform some action such as executing a Python function or submitting a Spark Job.

(e.g.) BashOperator, PythonOperator, DockerOperator, OracleOperator

### Transfer Operators:

Transfer Operators move data between systems such as from Hive to Mysql or from S3 to Hive.

(e.g.) GenericTransfer,MsSqlToHiveTransfer, RedshiftToS3Transfer

### Operator Properties:

| Property                  | Desc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Default                |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------- |
| dag                       | a reference to the dag the task is attached to                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Mandatory param        |
| task_id                   | a unique, meaningful id for the task                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Mandatory param        |
| email                     | email to send notification if any                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | None                   |
| email_on_retry            | boolean flag to send email on the task retry                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | True                   |
| email_on_failure          | boolean flag to send email on the task failure                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | True                   |
| retries                   | the number of retries that should be performed before failing the task                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 0                      |
| retry_delay               | delay between retries                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | timedelta(seconds=300) |
| retry_exponential_backoff | maximum delay interval between retries                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | False                  |
| depends_on_past           | when set to true, task instances will run sequentially while relying on the previous task's schedule to succeed. The task instance for the start_date is allowed to run.                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | False                  |
| adhoc                     | Mark the task as `adhoc`. Adhoc tasks used for performing certain task-specific on demand                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | False                  |
| params                    | Parameters / variables pass to airflow task instances                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | None                   |
| priority_weight           | priority weight of this task against other task. This allows the executor to trigger higher priority tasks before others when things get backed up.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 1                      |
| pool                      | the slot pool this task should run in, slot pools are a way to limit concurrency for certain tasks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | None                   |
| sla                       | time by which the job is expected to succeed. Note that this represents the \`\`timedelta\`\` after the period is closed. For example if you set an SLA of 1 hour, the scheduler would send dan email soon after `1:00AM` on the `2016-01-02` if the `2016-01-01` instance has not succeeded yet. The scheduler pays special attention for jobs with an SLA and sends alert emails for sla misses. SLA misses are also recorded in the database for future reference. All tasks that share the same SLA time get bundled in a single email, sent soon after that time. SLA notification are sent once and only once for each task instance. | None                   |
| execution_timeout         | max time allowed for the execution of this task instance, if it goes beyond it will raise and fail.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | None                   |
| task_concurrency          | When set, a task will be able to limit the concurrent runs across execution_dates                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | None                   |

### Bash Operators:

Execute a Bash script, command or set of commands. (e.g.) Bash Operator to clean /tmp files periodically.

```python
clean_tmp_dir = BashOperator(
    task_id='clean_tmp_dir',
    bash_command='find /tmp -mtime +2 -type f -exec rm -rf {} \;',
    dag='cleaner_dag'
)
```

### Python Operators:

Executes a Python callable method.

```python
def my_sleeping_function(random_base):
    """This is a function that will run within the DAG execution"""
    time.sleep(random_base)

for i in range(10): # loop in to create dynamic operators.
    task = PythonOperator(
        task_id='sleep_for_' + str(i), # task id should be unique
        python_callable=my_sleeping_function, # python callable method
        op_kwargs={'random_base': float(i) / 10}, # pass the method argument here
        dag=dag)
```

### Sensor Operators:

The Sensor operators trigger downstream tasks in the dependency graph when a specific criterion is met, for example checking for a particular file becoming available on S3 before using it downstream. Sensors are a dominant feature of Airflow allowing us to create complex workflows and efficiently manage their preconditions.

(e.g.) S3KeySensors, HivePartitionSensor, ExternalTaskSensor, TimeSensor

### Operator List

Operators detail list [available in here](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/operators/index.html?highlight=operators#module-airflow.operators)

### Sensor List

Sensors detail list [available in here](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/index.html?highlight=sensor#module-airflow.sensors)
